import React, { useState, useRef, useEffect } from 'react';

const synthesisAvailable = typeof window !== 'undefined' && 'speechSynthesis' in window;

interface VoiceMessage {
  role: 'user' | 'assistant';
  text: string;
  timestamp: string;
  isVoiceInput?: boolean;
}

export default function VoiceAssistant() {
  const [messages, setMessages] = useState<VoiceMessage[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [recognizedText, setRecognizedText] = useState('');

  // ‚úÖ –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ø–∞–º–∞ (2 —Å)
  const lastReqRef = useRef<number>(0);

  // ‚úÖ AbortController –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è —Å—Ç–∞—Ä–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
  const abortRef = useRef<AbortController | null>(null);

  const messagesEndRef = useRef<HTMLDivElement>(null);

  /* ---------- helpers ---------- */
  const scrollToBottom = () =>
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  /* ---------- –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ ---------- */
  const sendMessage = async (text: string, isVoiceInput = false) => {
    if (!text.trim()) return;

    // ‚úÖ –∞–Ω—Ç–∏-—Å–ø–∞–º
    const now = Date.now();
    if (now - lastReqRef.current < 2000) {
      window.toast?.('–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º');
      return;
    }
    lastReqRef.current = now;

    // ‚úÖ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∑–∞–ø—Ä–æ—Å, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –ª–µ—Ç–∏—Ç
    if (abortRef.current) {
      abortRef.current.abort();
      abortRef.current = null;
    }

    const userMsg: VoiceMessage = {
      role: 'user',
      text,
      timestamp: new Date().toISOString(),
      isVoiceInput,
    };

    setMessages((m) => [...m, userMsg]);
    setIsLoading(true);

    // ‚úÖ —á–∏—Å—Ç–∏–º —Å—Ç–∞—Ä—ã–µ ¬´–æ—à–∏–±–∫–∏¬ª –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (—á—Ç–æ–±—ã –Ω–µ –ø–ª–æ–¥–∏–ª–∏—Å—å)
    setMessages((m) =>
      m.filter((msg) => !(msg.role === 'assistant' && msg.text.includes('–û—à–∏–±–∫–∞')))
    );

    const controller = new AbortController();
    abortRef.current = controller;

    try {
      const res = await fetch('/api/proxy', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          inputs: text,
          systemPrompt: `–¢—ã ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∫–æ–ª–æ—Ä–∏—Å—Ç–∞. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ —Å—É—â–µ—Å—Ç–≤—É.`,
        }),
        signal: controller.signal,
        timeout: 30000, // 30 —Å —Ç–∞–π–º–∞—É—Ç
      });

      if (!res.ok) {
        // ‚úÖ —Ç–æ—á–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞
        const details = await res.text();
        throw new Error(`–°–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª ${res.status}: ${details}`);
      }

      const json = await res.json();
      const assistantMsg: VoiceMessage = {
        role: 'assistant',
        text: json.reply || '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞',
        timestamp: new Date().toISOString(),
      };

      setMessages((m) => [...m, assistantMsg]);
    } catch (err: any) {
      // ‚úÖ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
      let userText = '–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.';
      if (err.name === 'AbortError') userText = '–ó–∞–ø—Ä–æ—Å –æ—Ç–º–µ–Ω—ë–Ω.';
      if (err.message.includes('500')) userText = '–°–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –º–∏–Ω—É—Ç—É.';

      const errorMsg: VoiceMessage = {
        role: 'assistant',
        text: userText,
        timestamp: new Date().toISOString(),
      };
      setMessages((m) => [...m, errorMsg]);

      // ‚úÖ –ª–æ–≥ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
      console.error('[VoiceAssistant] Fetch error:', err);
    } finally {
      // ‚ùó‚ùó‚ùó –≥–ª–∞–≤–Ω–æ–µ: –≤—Å–µ–≥–¥–∞ —Å–Ω–∏–º–∞–µ–º —Ñ–ª–∞–≥
      setIsLoading(false);
      abortRef.current = null;
    }
  };

  /* ---------- –∫–Ω–æ–ø–∫–∞ ¬´–°—Ç–æ–ø¬ª ---------- */
  const stopSpeaking = () => {
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      window.speechSynthesis.cancel();
    }
    // ‚úÖ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –µ—â—ë –ª–µ—Ç–∏—Ç ‚Äî –ø—Ä–µ—Ä—ã–≤–∞–µ–º
    if (abortRef.current) {
      abortRef.current.abort();
      abortRef.current = null;
    }
    setIsLoading(false);
  };

  /* ---------- —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ ---------- */
  useEffect(() => {
    if (typeof window === 'undefined') return;
    const SpeechRecognition =
      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) return;

    const rec = new SpeechRecognition();
    rec.lang = 'ru-RU';
    rec.interimResults = true;
    rec.continuous = false;

    rec.onresult = (e: any) => {
      let final = '';
      for (let i = e.resultIndex; i < e.results.length; i++) {
        const t = e.results[i][0].transcript;
        if (e.results[i].isFinal) final = t;
      }
      setRecognizedText(final);
    };

    rec.onerror = () => setIsRecording(false);
    rec.onend = () => setIsRecording(false);

    recognitionRef.current = rec;
  }, []);

  const toggleRecording = () => {
    if (!recognitionRef.current) return;
    if (isRecording) {
      recognitionRef.current.stop();
    } else {
      setRecognizedText('');
      recognitionRef.current.start();
      setIsRecording(true);
    }
  };

  /* ---------- —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ ---------- */
  const speakResponse = (text: string) => {
    if (typeof window === 'undefined') return;
    if (!('speechSynthesis' in window)) return;
    window.speechSynthesis.cancel();
    const utter = new SpeechSynthesisUtterance(text);
    utter.lang = 'ru-RU';
    utter.rate = 0.9;
    window.speechSynthesis.speak(utter);
  };

  /* ---------- UI ---------- */
  return (
    <div className="max-w-4xl mx-auto p-4">
      {/* ... –≤–∞—à —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π JSX ... */}

      {/* –ö–ù–û–ü–ö–ò –£–ü–†–ê–í–õ–ï–ù–ò–Ø */}
      <div className="flex gap-3 mt-4">
        <button
          onClick={toggleRecording}
          disabled={isLoading}
          className={`relative w-24 h-24 rounded-full flex items-center justify-center text-4xl transition-all
            ${isRecording ? 'bg-red-500 animate-pulse-record' : 'bg-gradient-to-r from-purple-500 to-pink-500 hover:scale-105'}
            ${isLoading ? 'opacity-50 cursor-not-allowed' : ''}`}
        >
          {isRecording ? '‚èπÔ∏è' : 'üé§'}
        </button>

        {isLoading && (
          <button
            onClick={stopSpeaking}
            className="px-4 py-2 bg-gray-200 hover:bg-gray-300 rounded-lg"
          >
            ‚è∏Ô∏è –°—Ç–æ–ø
          </button>
        )}
      </div>

      {/* –ë–´–°–¢–†–´–ï –ü–û–î–°–ö–ê–ó–ö–ò */}
      <div className="mt-6 bg-purple-50 p-4 rounded-lg">
        <h3 className="font-bold text-purple-900 mb-2">–ß—Ç–æ –º–æ–∂–Ω–æ —Å–ø—Ä–æ—Å–∏—Ç—å:</h3>
        <div className="flex flex-wrap gap-2">
          {['–ö–∞–∫–æ–π –æ–∫–∏—Å–ª–∏—Ç–µ–ª—å –Ω–∞ –∫–æ—Ä–Ω–∏?', '–ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å –∂—ë–ª—Ç—ã–º –æ—Ç—Ç–µ–Ω–∫–æ–º?', '–ö–∞–∫ —Å–º–µ—à–∞—Ç—å 7,5 % –æ–∫–∏—Å–ª–∏—Ç–µ–ª—å?'].map((t) => (
            <button
              key={t}
              onClick={() => sendMessage(t)}
              disabled={isLoading}
              className="px-3 py-1 bg-white border border-purple-200 rounded-full text-sm hover:bg-purple-100 disabled:opacity-50"
            >
              {t}
            </button>
          ))}
        </div>
      </div>
    </div>
  );
}
